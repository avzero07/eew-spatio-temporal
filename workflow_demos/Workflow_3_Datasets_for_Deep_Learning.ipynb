{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb69549",
   "metadata": {},
   "source": [
    "# Workflow 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056062e",
   "metadata": {},
   "source": [
    "### Import est_lib Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c94c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from est_lib.util.obspy_util import *\n",
    "from est_lib.util.obspy_plot import ray_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35fdf2",
   "metadata": {},
   "source": [
    "### Import Some other est_lib Functions Used in this Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6279f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from est_lib.nn.cp_line_simple import cp_line_simple\n",
    "from est_lib.dataset.seismic_dataset_new import EQDataset, get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036e2563",
   "metadata": {},
   "source": [
    "### Import Some other Functions that are also used in this Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38bda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a2338",
   "metadata": {},
   "source": [
    "### Specify Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0616460",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = ['HOLB','PACB','WOSB','HOPB']\n",
    "channel_list = ['HHE','HHN','HHZ']\n",
    "\n",
    "# Note: channel_list specifies the channels of interest\n",
    "#    In this example, we retrieve velocity data for \n",
    "#    all three directions (E, N and Z). To get acceleration\n",
    "#    data replace with ['HNE','HNN','HNZ']\n",
    "\n",
    "'''\n",
    "Specify a Time of interest. Note that that the timestamp\n",
    "is in UTC.\n",
    "'''\n",
    "event_time = \"2019-12-25T03:36:01.578000Z\"\n",
    "event_lat = 50.6081\n",
    "event_lon = -129.9656\n",
    "event = ('6.3',event_lat,event_lon,event_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b7b4f",
   "metadata": {},
   "source": [
    "### Retrieve Station Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a929597",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the inventory_retriever function to retrieve\n",
    "metadata about stations in station_list\n",
    "'''\n",
    "station_metadata = inventory_retriever(sta_list=station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264b1d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory created at 2021-08-06T03:09:25.000000Z\n",
      "\tCreated by: IRIS WEB SERVICE: fdsnws-station | version: 1.1.47\n",
      "\t\t    http://service.iris.edu/fdsnws/station/1/query?network=CN&station=H...\n",
      "\tSending institution: IRIS-DMC (IRIS-DMC)\n",
      "\tContains:\n",
      "\t\tNetworks (1):\n",
      "\t\t\tCN\n",
      "\t\tStations (4):\n",
      "\t\t\tCN.HOLB (Holberg, BC, CA)\n",
      "\t\t\tCN.HOPB (Hope, BC, CA)\n",
      "\t\t\tCN.PACB (Port Alice, BC, CA)\n",
      "\t\t\tCN.WOSB (Woss, BC, CA)\n",
      "\t\tChannels (65):\n",
      "\t\t\tCN.HOLB..EHZ, CN.HOLB..HHZ (4x), CN.HOLB..HHN (4x), \n",
      "\t\t\tCN.HOLB..HHE (4x), CN.HOLB..HNZ (3x), CN.HOLB..HNN (3x), \n",
      "\t\t\tCN.HOLB..HNE (3x), CN.HOPB..BHZ (2x), CN.HOPB..BHN (2x), \n",
      "\t\t\tCN.HOPB..BHE (2x), CN.HOPB..HHZ (2x), CN.HOPB..HHN (2x), \n",
      "\t\t\tCN.HOPB..HHE (2x), CN.HOPB..HNZ (2x), CN.HOPB..HNN (2x), \n",
      "\t\t\tCN.HOPB..HNE (2x), CN.PACB..HHZ (2x), CN.PACB..HHN (2x), \n",
      "\t\t\tCN.PACB..HHE (2x), CN.PACB..HNZ (2x), CN.PACB..HNN (2x), \n",
      "\t\t\tCN.PACB..HNE (2x), CN.WOSB..EHZ, CN.WOSB..HHZ, CN.WOSB..HHN, \n",
      "\t\t\tCN.WOSB..HHE, CN.WOSB..HNZ (3x), CN.WOSB..HNN (3x), \n",
      "\t\t\tCN.WOSB..HNE (3x)\n"
     ]
    }
   ],
   "source": [
    "print(station_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51218207",
   "metadata": {},
   "source": [
    "### Retrieve Seismic Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446efb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the stream_retriever function to retrieve\n",
    "seismic streams from an IRIS' FDSN compliant\n",
    "datacenter.\n",
    "\n",
    "We instruct the function to fetch data starting\n",
    "from 500 seconds before the specified time upto\n",
    "150 seconds after.\n",
    "\n",
    "That is, if the time of interest is at 0, we\n",
    "fetch data from -500 to 1500.\n",
    "'''\n",
    "\n",
    "seconds_before = 500\n",
    "seconds_after = 1500\n",
    "\n",
    "'''\n",
    "Datasets for supervised deep learning have a training\n",
    "set and a test set. Let us split the data we retrieve\n",
    "such that data related to all but the last station (HOPB)\n",
    "in station_list forms the training set and the data from\n",
    "HOPB forms the test set.\n",
    "'''\n",
    "\n",
    "train_data = stream_retriever(event_time=event_time,\n",
    "                        time_format='string',\n",
    "                        seconds_before = 500,\n",
    "                        seconds_after = 1500,\n",
    "                        sta_list = station_list[0:-1],\n",
    "                        channel_list = channel_list)\n",
    "\n",
    "test_data = stream_retriever(event_time=event_time,\n",
    "                        time_format='string',\n",
    "                        seconds_before = 500,\n",
    "                        seconds_after = 1500,\n",
    "                        sta_list = station_list[-1:],\n",
    "                        channel_list = channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7ac6f",
   "metadata": {},
   "source": [
    "### Write Streams to Local Filesystem\n",
    "\n",
    "#### Specify the Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b586945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.abspath(os.path.join('./Data'))\n",
    "if(not os.path.isdir(filepath)):\n",
    "    os.mkdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8409cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\Desktop\\eew-spatio-temporal\\workflow_demos\\Data\n"
     ]
    }
   ],
   "source": [
    "print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a431b4",
   "metadata": {},
   "source": [
    "#### Write Train File to File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af836664",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_f_path = os.path.join(filepath,'train_x.npy')\n",
    "train_x_file = stream_data_writer(train_data,\n",
    "                              station_metadata,\n",
    "                              train_x_f_path,\n",
    "                              station_list[0:-1],\n",
    "                              channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699b093",
   "metadata": {},
   "source": [
    "#### Write Test File to File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ed0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_f_path = os.path.join(filepath,'train_y.npy')\n",
    "train_y_file = stream_data_writer(test_data,\n",
    "                              station_metadata,\n",
    "                              train_y_f_path,\n",
    "                              station_list[-1:],\n",
    "                              channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb805c3",
   "metadata": {},
   "source": [
    "### Write Inventory Data to Local Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d27ed232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aksha\\\\Desktop\\\\eew-spatio-temporal\\\\workflow_demos\\\\Data\\\\demo_stations_metadata.xml'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Use inventory_writer to save station_metadata to a\n",
    "file in the local filesystem in the XML format.\n",
    "Specify a path to the new file as the second argument.\n",
    "'''\n",
    "metadata_file = os.path.join(filepath,'demo_stations_metadata.xml')\n",
    "inventory_writer(station_metadata,metadata_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cb858",
   "metadata": {},
   "source": [
    "### Initialize a PyTorch Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d4b49",
   "metadata": {},
   "source": [
    "PyTorch provides a DataSet construct (class) that can be used as a model to build custom DataSet classes for different kinds of data. EQDataset is one such custom dataset that is available as part of est_lib.\n",
    "\n",
    "Reference to PyTorch Documentation: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01b2964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EQDataset(metadata_file,\n",
    "                    train_x_file,train_y_file,\n",
    "                    sta_list=station_list,\n",
    "                    chan_list=channel_list,\n",
    "                    ip_dim=len(channel_list),\n",
    "                    num_nodes=len(station_list[0:-1]),\n",
    "                    seq_length=500,horizon=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da549df",
   "metadata": {},
   "source": [
    "### Initialize a Dataset Loader\n",
    "\n",
    "DataLoaders are used to iterate over datasets and retrieve a batch of samples. Dataloaders are easy to use and work directly with PyTorch compatible DataSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565c9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1f84e",
   "metadata": {},
   "source": [
    "### Initialize a Neural Network\n",
    "\n",
    "est_lib provides a Neural Network model called, cp_line_simple, which can be used for regression where it can be trained to make a prediction about seismic waves at a location based on the waves recorded at other locations.\n",
    "\n",
    "An untrained version of this network is initialized and used in this notebook merely to illustrate how est_lib fits into a deep learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc74c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cp_line_simple(num_in_nodes=len(station_list[0:-1]),\n",
    "                     feat_size=len(channel_list)).to(get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736dbfb0",
   "metadata": {},
   "source": [
    "### Pass a Datapoint from the PyTorch Dataset into the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c81310b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66c602cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_output = net(data_point[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54f60fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.4189]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[0.2631]], device='cuda:0', grad_fn=<AddmmBackward>), tensor([[-0.2421]], device='cuda:0', grad_fn=<AddmmBackward>)]\n"
     ]
    }
   ],
   "source": [
    "print(network_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
